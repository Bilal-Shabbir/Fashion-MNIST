# -*- coding: utf-8 -*-
"""withGpu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yOmMrgxkF5CDjyH4iygTbaK1QXKw5waA
"""

from collections import namedtuple
import json
from multiprocessing.connection import wait
import time
from typing import OrderedDict
from sklearn.utils import shuffle
import torch
import torchvision
import torchvision.transforms as transforms
import pandas as pd
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from itertools import product
from torch.utils.tensorboard import SummaryWriter

print(torch.__version__)
print(torchvision.__version__)

train_set = torchvision.datasets.FashionMNIST(
    root='./data',
    train=True,
    download=True,
    transform=transforms.Compose(
        [transforms.ToTensor()
        ,#         #transforms.Normalize(mean, std)
        ]
    )
)

type(train_set)

class Network(nn.Module):
  def __init__(self):
    super(Network, self).__init__()       # out_channels mean no of filters applied
    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)  # kernal size mean filter size
    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)
                                           # default stride for Conv2d is (1, 1)
    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)  # fully connected layer
    self.fc2 = nn.Linear(in_features=120, out_features=60)
    self.out = nn.Linear(in_features=60, out_features=10)
                # Conv2d and Linear are the instances of objects
  def forward(self, t):
    # (1) input layer
    t = t
    # (2) hidden conv layer
    t = self.conv1(t)
    t = F.relu(t)
    t = F.max_pool2d(t, kernel_size=2, stride=2)

    #(3) conv layer
    t = self.conv2(t)
    t = F.relu(t)
    t = F.max_pool2d(t, kernel_size=2, stride=2)

    # (4) linear layer
    t = t.reshape(-1, 12 *4* 4)
    t = self.fc1(t)
    t = F.relu(t)

    # (5)
    t = self.fc2(t)
    t = F.relu(t)

    #(6) output layer
    t = self.out(t)

    return t

class RunBuilder():
  @staticmethod
  def get_runs(params):
    Run = namedtuple('Run', params.keys())
    runs=[]
    for v in product(*params.values()):
       runs.append(Run(*v))
    return runs

class RunManager():
    def __init__(self):
        
        self.epoch_count =0
        self.epoch_num_correct =0
        self.epoch_start_time = None
        self.epoch_loss =0

        self.run_params = None
        self.run_count = 0
        self.run_data = []
        self.run_start_time = None

        self.network = None
        self.loader = None
        self.tb = None

    def begin_run(self, run, network, loader):
        self.run_start_time = time.time()

        self.run_params = run  # parameters
        self.run_count +=1

        self.network = network 
        self.loader = loader  # dataloader
        self.tb = SummaryWriter(comment=f'-{run}')  # comment will let identify inside tensorboarf

        images , labels = next(iter(self.loader))
        grid = torchvision.utils.make_grid(images)

        self.tb.add_image('images', grid)
        self.tb.add_graph(self.network,
                          images.to(getattr(run,'device', 'cpu')))

    def end_run(self):
        self.tb.close()
        self.epoch_count = 0

    def begin_ecpoch(self):
        self.epoch_start_time = time.time()

        self.epoch_count +=1
        self.epoch_loss = 0
        self.epoch_num_correct =0

    def end_epoch(self):

        epoch_duration = time.time() - self.epoch_start_time
        run_duration = time.time()

        loss = self.epoch_loss / len(self.loader.dataset)
        accuracy = self.epoch_num_correct / len(self.loader.dataset)

        self.tb.add_scalar('Loss', loss, self.epoch_count)
        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)

        for name, param in self.network.named_parameters():
            self.tb.add_histogram(name, param, self.epoch_count)
            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)

        results = OrderedDict()

        results["run"] = self.run_count
        results["epoch"] = self.epoch_count
        results["loss"] = loss
        results["accuracy"] = accuracy
        results['epoch_duration'] = epoch_duration
        results['run_duration'] = run_duration
        for k,v in self.run_params._asdict().items():  results[k] = v
        self.run_data.append(results)
        df = pd.DataFrame.from_dict(self.run_data, orient='columns')
        #print(df)

    def track_loss(self, loss):
        self.epoch_loss += loss.item() * self.loader.batch_size

    def track_num_correct(self, preds, labels):
        self.epoch_num_correct += self._get_num_correct(preds, labels)

    @torch.no_grad()
    def _get_num_correct(self, preds, labels):
        return preds.argmax(dim=1).eq(labels).sum().item()

    def save(self, fileName):

        pd.DataFrame.from_dict(
            self.run_data,
            orient='columns'
        ).to_csv(f'{fileName}.csv')

        with open(f'{fileName}'.json, 'w', encoding='utf-8') as f:
            json.dump(self.run_data, f, ensure_ascii=False, indent=4)

# easy way of normalizaiton
loader = torch.utils.data.DataLoader(train_set, batch_size=len(train_set), num_workers=1)
data = next(iter(loader))
mean = data[0].mean()
std=data[0].std()

mean, std

# hard way
loader = torch.utils.data.DataLoader(train_set, batch_size=1000, num_workers=1)
num_pixel = len(train_set)*28*28
total_sum =0
for batch in loader: total_sum +=batch[0].sum()
mean = total_sum / num_pixel

sum_of_squre_error =0
for batch in loader: sum_of_squre_error += ((batch[0]-mean).pow(2)).sum()
std = torch.sqrt(sum_of_squre_error / num_pixel)

mean, std





parameters = dict(
    lr = [0.01],
    #batch_size = [1000, 10000],
    num_workers=[0, 1],
    device = ['cuda']
)

m = RunManager()

for run in RunBuilder.get_runs(parameters): 
   device = torch.device(run.device)
   network = Network().to(device)
   #comment = f' batch_size={batch_size} lr={lr}'
   #comment = f'-{run}'
   loader = torch.utils.data.DataLoader(train_set, batch_size=run.batch_size)
   optimizer = optim.Adam(network.parameters(), run.lr)
  

   m.begin_run(run, network, loader)
   
   #comment = f'batch_size={batch_size} lr={lr}'
   
   for epoch in range(5):
     m.begin_ecpoch()
     for batch in loader:
         images= batch[0].to(device)
         labels=batch[1].to(device)

         preds = network(images)
         loss = F.cross_entropy(preds, labels) # calculating loss

         optimizer.zero_grad()
         loss.backward()  # calculating the gradients by back propogation
         optimizer.step()  # optimizer already have the weights
                     # this will update the weights
         m.track_loss(loss)
         m.track_num_correct(preds, labels)
     m.end_epoch()
   m.end_run()

pd.DataFrame.from_dict(m.run_data, orient='columns').sort_values('accuracy', ascending=False)

